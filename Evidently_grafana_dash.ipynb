{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1f49f7-f010-4b30-97bb-2fa15211355b",
   "metadata": {},
   "source": [
    "Complete Guide to Effortless ML Monitoring with Evidently.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbe3b5-176c-4f78-a5b3-bc557203566f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install evidently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a391831-e434-4ef8-b6e9-e9d2da2032b9",
   "metadata": {},
   "source": [
    "Integrate Evidently with Grafana Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909183e4-dea4-4d5f-8913-41af708e9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can integrate Evidently, with Grafana Dashboard, we use PostgreSQL database, to store the metrics results.\n",
    "\n",
    "#Our docker file, in which it consists of all necessary dependencies.\n",
    "\n",
    "version: '3.7'\n",
    "\n",
    "volumes:\n",
    "    grafana_data: {}\n",
    "\n",
    "networks:\n",
    "  front-tier:\n",
    "  back-tier:\n",
    "\n",
    "services:\n",
    "  db:\n",
    "    image: postgres\n",
    "    restart: always\n",
    "    environment:\n",
    "      POSTGRES_PASSWORD: example\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    networks:\n",
    "      - back-tier\n",
    "\n",
    "  adminer:\n",
    "    image: adminer\n",
    "    restart: always\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    networks:\n",
    "      - back-tier\n",
    "      - front-tier\n",
    "\n",
    "  grafana:\n",
    "    image: grafana/grafana:8.5.21\n",
    "    user: \"472\"\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    volumes:\n",
    "      - ./config/grafana_datasources.yaml:/etc/grafana/provisioning/datasources/datasource.yaml:ro\n",
    "      - ./config/grafana_dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml:ro\n",
    "      - ./dashboards:/opt/grafana/dashboards\n",
    "    networks:\n",
    "      - back-tier\n",
    "      - front-tier\n",
    "    restart: always  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1af33-b341-4519-b564-67f1cf272da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Necessary Libraries\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "from evidently.metric_preset import DataQualityPreset\n",
    "from sklearn import datasets\n",
    "from evidently.test_preset import DataQualityTestPreset\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import ColumnDriftMetric, Dataset\n",
    "\n",
    "DriftMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6bc5e5-01db-4b3a-97c0-200192a5d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Configure Logging Settings\n",
    "# Configure logging settings\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s]: %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f30eb-5770-41bb-b4b4-f73877c9d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define SQL Statement to Create a Table for Storing Drift Metrics\n",
    "# Define SQL statement to create table for storing drift metrics\n",
    "create_table_statement = \"\"\"\n",
    "drop table if exists drift_metrics;\n",
    "create table drift_metrics(\n",
    "\ttimestamp timestamp,\n",
    "\ttarget_drift float,\n",
    "\tshare_drifted_columns float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a4eca-03de-4c69-846a-51933225f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Read Dataset\n",
    "\n",
    "# Read dataset\n",
    "df=pd.read_csv(\"DelayedFlights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4f9a1-509d-4987-8d69-205236f4dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define Reference and Production Simulation Data\n",
    "# Define reference and production simulation data\n",
    "reference_data = df[5000:5500]\n",
    "prod_simulation_data = df[7000:]\n",
    "mini_batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48352e0-958f-42a1-8e64-896ee715670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Prepare Database for Storing Drift Metrics\n",
    "# Function to prepare database for storing drift metrics\n",
    "def prep_db():\n",
    "    # Connect to PostgreSQL and create database if it doesn't exist\n",
    "    with psycopg.connect(\"host=localhost port=5432 user=postgres password=example\", autocommit=True) as conn:\n",
    "        res = conn.execute(\"SELECT 1 FROM pg_database WHERE datname='test'\")\n",
    "        if len(res.fetchall()) == 0:\n",
    "            conn.execute(\"create database test;\")\n",
    "        # Connect to the 'test' database and create table for drift metrics\n",
    "        with psycopg.connect(\"host=localhost port=5432 dbname=test user=postgres password=example\") as conn:\n",
    "            conn.execute(create_table_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ce8ca-ef50-4f25-9020-41092277ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Calculate Drift Metrics and Store them in PostgreSQL\n",
    "\n",
    "# Function to calculate drift metrics and store them in PostgreSQL\n",
    "def calulate_metrics_postgresql(curr, i):\n",
    "    # Initialize report for data quality analysis\n",
    "    report = Report(metrics=[\n",
    "        DataQualityPreset(),\n",
    "    ])\n",
    "\n",
    "    # Run the report on reference and current data\n",
    "    report.run(reference_data=reference_data, current_data=prod_simulation_data[i*mini_batch_size : (i+1)*mini_batch_size])\n",
    "    result = report.as_dict()\n",
    "\n",
    "    # Extract drift metrics from the report results\n",
    "    target_drift = result['metrics'][1]['result']['drift_score']\n",
    "    share_drifted_columns = result['metrics'][0]['result']['share_of_drifted_columns']\n",
    "\n",
    "    # Insert metrics into the 'drift_metrics' table\n",
    "    curr.execute(\n",
    "        \"insert into drift_metrics(timestamp, target_drift, share_drifted_columns) values (%s, %s, %s)\",\n",
    "        (datetime.datetime.now(), target_drift, share_drifted_columns)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40547822-df67-4792-9ad9-e49a42ff831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Perform Batch Monitoring and Backfill Drift Metrics into PostgreSQL\n",
    "# Function to perform batch monitoring and backfill drift metrics into PostgreSQL\n",
    "def batch_monitoring_backfill():\n",
    "    # Prepare the database\n",
    "    prep_db()\n",
    "    # Connect to the 'test' database and iterate over mini-batches of data\n",
    "    with psycopg.connect(\"host=localhost port=5432 dbname=test user=postgres password=example\", autocommit=True) as conn:\n",
    "        for i in range(50):\n",
    "            with conn.cursor() as curr:\n",
    "                # Calculate and store drift metrics for each mini-batch\n",
    "                calulate_metrics_postgresql(curr, i)\n",
    "            # Log progress and wait before processing the next mini-batch\n",
    "            logging.info(\"data sent\")\n",
    "            time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1f340-042a-4d9d-bf67-3db2772f75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Execute the Project\n",
    "# Entry point of the script\n",
    "if __name__ == '__main__':\n",
    "    batch_monitoring_backfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdea52c-1fb4-4155-bb4d-b32abf7043e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute the docker file, \n",
    "\n",
    "docker compose-up --build\n",
    "python grafana.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3c116-92bb-40fc-834c-8b01f43e3548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c08f7c-8505-4417-a34f-bdb3c0c74711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca8a09-af25-465b-84e2-1db0d06ff0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed51f0a-a2d6-4df5-8a2b-5510b4252162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb4ece-96a9-4ea8-85fc-2519faa37cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e3896-1d7e-44f3-af29-8791c249c1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66009e20-8ba5-44e8-8f5e-614d8bf729aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd01f7-c092-4b77-afca-e85f6a25eeba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26671fbd-f564-44fa-a770-dc367ce94506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4b465-192b-4efa-8f53-fb43a7bc8f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbbecc-4dce-48a3-960e-bf03e6a8f42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86f2d6-1454-442f-8df2-e9b2f3f817c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
